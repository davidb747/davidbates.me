---
layout: article
title: 3. Classification
tags: Hands-On
sidebar:
  nav: docs-en
aside:
  toc: true
---

# Remarks
본 포스팅은 **Hands-On Machine Learning with Scikit-Learn & TensorFlow ([Auérlien Géron](https://github.com/ageron/handson-ml), [박해선(역)](https://github.com/rickiepark/handson-ml), 한빛미디어)** 를 기반으로 작성되었습니다.

<!--more-->

---

# Import libraries and functions
{% highlight python linenos %}
import numpy as np
import pandas as pd
import matplotlib
import matplotlib.pyplot as plot
%matplotlib inline

p = lambda *x: print(*x)

# plotting functions
def plot_digit(data):
    image = data.reshape(28, 28)
    plt.imshow(image, cmap=matplotlib.cm.binary)
    plt.axis('off')

def plot_digits(instances, images_per_row=10, **options):
    size = 28
    images_per_row = min(len(instances), images_per_row)
    images = [instance.reshape(size,size) for instance in instances]
    n_rows = (len(instances) - 1) // images_per_row + 1
    row_images = []
    n_empty = n_rows * images_per_row - len(instances)
    images.append(np.zeros((size, size * n_empty)))
    for row in range(n_rows):
        rimages = images[row * images_per_row : (row + 1) * images_per_row]
        row_images.append(np.concatenate(rimages, axis=1))
    image = np.concatenate(row_images, axis=0)
    plt.imshow(image, cmap = matplotlib.cm.binary, **options)
    plt.axis("off")
{% endhighlight %}


# I. MNIST
{% highlight python linenos %}
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split

# Load MNIST
mnist = fetch_openml('mnist_784', version=1)
X, y = mnist['data'], mnist['target'].astype(np.int)

# Generate train, test set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/7, stratify=y, random_state=42)
X_train.shape, X_test.shape, y_train.shape, y_test.shape
{% endhighlight %}


# II. Training a Binary Classifier
{% highlight python linenos %}
from sklearn.linear_model import SGDClassifier

# Train 5 or not binary classifier
y_train_5, y_test_5 = (y_train == 5), (y_test == 5)
some_digit = 42

sgd_clf = SGDClassifier(max_iter=5, random_state=42)
sgd_clf.fit(X_train, y_train_5)
sgd_clf.predict([some_digit])
{% endhighlight %}


# III. Performance Measures
## 1. Measuring Accuracy Using Cross-Validation
```p
from sklearn.model_selection import cross_val_score

cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring='accuracy')
```

## 2. Confusion Matrix
```p
from sklearn.model_selection import cross_val_predict
from sklearn.metrics import confusion_matrix

y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)
confusion_matrix(y_train_5, y_train_pred)
```

## 3. Precision and Recall
자세한 설명은 [https://djy-git.github.io/2019/07/17/confusion-matrix.html](https://djy-git.github.io/2019/07/17/confusion-matrix.html) 참조
```p
from sklearn.metrics import precision_score, recall_score, f1_score

precision_score(y_train_5, y_train_pred)
recall_score(y_train_5, y_train_pred)
f1_score(y_train_5, y_train_pred)
```

## 4. Precision/Recall TradeOff
```p
# predict() is equal to 'decision_funcion() > threshold=0'
y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3, method='decision_function')
```

## 5. The ROC Curve
PR Curve와 ROC Curve는 [https://djy-git.github.io/2019/07/18/curves.html](https://djy-git.github.io/2019/07/18/curves.html)을 참조

# IV. Multiclass Classification
```p
# SGDClassifier uses OvA strategy when performed in multiclass classification
sgd_clf.fit(X_train, y_train)
some_digit_scores = sgd_clf.decision_function([some_digit])
sgd_clf.classes_
```
OvA, OvO에 대한 설명은 [https://djy-git.github.io/2019/07/13/ovaovr.html](https://djy-git.github.io/2019/07/13/ovaovr.html)
참조


# V. Error Analysis
